{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>PROJECT 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre_Process_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from math import sqrt\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from  matplotlib.colors  import ListedColormap\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from  sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two CSV files Audit_Risk.csv and Trial.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit=pd.read_csv('audit_risk.csv')\n",
    "trial=pd.read_csv('trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "audit.drop(['Prob','Detection_Risk'],axis=1)\n",
    "trial=trial.drop(['Sector_score', 'LOCATION_ID','PARA_A','SCORE_A','PARA_B','SCORE_B','Risk','TOTAL','numbers','History','Money_Value','Score'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to merge, a new index column is added\n",
    "audit['Project'] = audit.index.values\n",
    "trial['Project'] = trial.index.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(audit,trial, on='Project', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.LOCATION_ID.replace(['LOHARU', 'NUH','SAFIDON'], [10, 26,45], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LOCATION_ID']=df['LOCATION_ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treating the outliners in the data\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ((df[['PARA_A', 'Score_A', 'PARA_B', 'Score_B','Inherent_Risk','Money_Value']] < (Q1 - 30 * IQR)) \n",
    "        | (df[['PARA_A', 'Score_A', 'PARA_B', 'Score_B','Inherent_Risk','Money_Value']] > (Q3 + 30 * IQR)))\n",
    "#mask.sum()\n",
    "df[mask]= np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.fillna(df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Sector_score','LOCATION_ID','Project'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 31)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split dataset ( Audit_Risk as target for regression)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['Audit_Risk','Risk'], axis = 1)\n",
    "y = df['Audit_Risk']\n",
    "X.columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X,y, random_state = 0)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reduce loss of information, we already treated outliners,so we used MinMaxScaler which essentially shrinks the range such that the range is now between 0 and 1 (or -1 to 1 if there are negative values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering ``Audit Risk`` as the target column for classification tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply any two models with bagging :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = BaggingRegressor(DecisionTreeRegressor(),\n",
    "                                n_jobs=-1,bootstrap=True,\n",
    "                                random_state=0).fit(X_train, y_train)\n",
    "\n",
    "pred = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_1 = ensemble.score(X_test, y_test)\n",
    "score_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ensemble_2 = BaggingRegressor(Ridge(),\n",
    "                                n_jobs=-1,bootstrap=True,\n",
    "                                random_state=0).fit(X_train, y_train)\n",
    "\n",
    "pred_2 = ensemble_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2 = ensemble_2.score(X_test, y_test)\n",
    "score_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two models with pasting :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pasting, change argument to bootstrap=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasting = BaggingRegressor(DecisionTreeRegressor(),\n",
    "                                n_jobs=-1,bootstrap=False,\n",
    "                                random_state=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_paste = pasting.predict(X_test)\n",
    "pred_paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_paste = pasting.score(X_test, y_test)\n",
    "score_paste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pasting_2 = BaggingRegressor(Ridge(),\n",
    "                                n_jobs=-1,bootstrap=False,\n",
    "                                random_state=0).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_pasting_2 = pasting_2.predict(X_test)\n",
    "pred_pasting_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_2_paste = pasting_2.score(X_test, y_test)\n",
    "score_2_paste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply any two models with adaboost boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score_list = []\n",
    "best_score = 0\n",
    "for n_estimators in [10, 50, 100]:\n",
    "    for learning_rate in [0.1, 0.5, 1]:\n",
    "        for n_neighbors in [1,2,3,4,5,6,7,8,9]:\n",
    "            regr = AdaBoostRegressor(KNeighborsRegressor(n_neighbors=n_neighbors),n_estimators=n_estimators,learning_rate=learning_rate,random_state=0)\n",
    "            regr.fit(X_train,y_train)\n",
    "            score = regr.score(X_test, y_test)\n",
    "            test_score_list.append(score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'n_estimators': n_estimators , 'learning_rate' : learning_rate,'n_neighbors': n_neighbors}\n",
    "                best_n = n_estimators\n",
    "                best_learning_rate= learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsRegressor(AdaBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression mode(1)\n",
    "regr_2 = AdaBoostRegressor(KNeighborsRegressor(n_neighbors = 5),n_estimators=10, learning_rate= 0.1,random_state=0)\n",
    "regr_2.fit(X_train, y_train)\n",
    "regr_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeRegressor(AdaBoostRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression mode(2)\n",
    "regr_2 = AdaBoostRegressor(DecisionTreeRegressor(),n_estimators=10, learning_rate= 0.1,random_state=0)\n",
    "regr_2.fit(X_train, y_train)\n",
    "regr_2.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply one model with gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingRegressor()\n",
    "clf.fit(X_train, y_train)\n",
    "# Make the prediction \n",
    "y_pred_gb = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, clf.predict(X_test))\n",
    "print(\"MSE: %.4f\" % mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred_gb, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title(\"Ground Truth vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = .95)\n",
    "pca.fit(X_train)\n",
    "\n",
    "#pca.fit(y_train.reshape(1, -1))\n",
    "#pca.fit(y_test.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = pca.transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "#y_train_reduced = pca.transform(y_train)\n",
    "#y_test_reduced = pca.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA().fit(X_train)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(570, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7315032159716541\n",
      "0.7583806301522309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_reduced, y_train)\n",
    "print(lreg.score(X_train_reduced, y_train))\n",
    "print(lreg.score(X_test_reduced, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.58677573 0.69708798 0.69649603 0.69560111 0.70003426]\n",
      "Average cross-validation score: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5)\n",
    "lreg_cv = LinearRegression()\n",
    "scores = cross_val_score(lreg_cv, X_train_reduced, y_train, cv = kfold)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Scores={}\n",
    "\n",
    "Regression_Scores.update({'Linear Regression': scores.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Model_name','Model_params','Train_score','Test_score','Average Cross Validation Score','Best Parameters']\n",
    "reg_model_para = pd.DataFrame(columns=columns)\n",
    "\n",
    "reg_model_para = reg_model_para.append({'Model_name':'Linear Regression',\n",
    "                                        'Model_params': '',\n",
    "                                        'Train_score': lreg.score(X_train_reduced, y_train),\n",
    "                                        'Test_score':lreg.score(X_test_reduced, y_test),\n",
    "                       'Average Cross Validation Score':scores.mean(),\n",
    "                       'Best Parameters':''},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_name</th>\n",
       "      <th>Model_params</th>\n",
       "      <th>Train_score</th>\n",
       "      <th>Test_score</th>\n",
       "      <th>Average Cross Validation Score</th>\n",
       "      <th>Best Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td></td>\n",
       "      <td>0.731503</td>\n",
       "      <td>0.758381</td>\n",
       "      <td>0.675199</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model_name Model_params  Train_score  Test_score  \\\n",
       "0  Linear Regression                  0.731503    0.758381   \n",
       "\n",
       "   Average Cross Validation Score Best Parameters  \n",
       "0                        0.675199                  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "grid_search = GridSearchCV(SVR(kernel='linear'), param_grid, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = grid_search.best_params_\n",
    "svr_linear = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Scores.update({'SVM Simple Regression':svr_linear})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para = reg_model_para.append({'Model_name':'SVR Linear Regressor',\n",
    "                                        'Model_params': 'c'',''gamma',\n",
    "                                        'Train_score': (grid_search.score(X_train_reduced, y_train)),\n",
    "                                        'Test_score': (grid_search.score(X_test_reduced, y_test)),\n",
    "                       'Average Cross Validation Score': svr_linear ,\n",
    "                       'Best Parameters':xy},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "grid_search = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yz = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Scores.update({'SVM RBF Kernel':scores.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para = reg_model_para.append({'Model_name':'SVR rbf kernal',\n",
    "                                        'Model_params': 'c'',''gamma',\n",
    "                                        'Train_score': (grid_search.score(X_train_reduced, y_train)),\n",
    "                                        'Test_score': (grid_search.score(X_test_reduced, y_test)),\n",
    "                       'Average Cross Validation Score': grid_search.best_score_ ,\n",
    "                       'Best Parameters':yz},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM poly regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_2 = param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "              'degree': [1,2,3,4,5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "grid_search = GridSearchCV(SVR(kernel='poly'), param_grid=params_grid_2 , cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zx = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Scores.update({'SVM poly Kernel':scores.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para = reg_model_para.append({'Model_name':'SVR poly kernal',\n",
    "                                        'Model_params': 'degree',\n",
    "                                        'Train_score': (grid_search.score(X_train_reduced, y_train)),\n",
    "                                        'Test_score': (grid_search.score(X_test_reduced, y_test)),\n",
    "                       'Average Cross Validation Score': grid_search.best_score_ ,\n",
    "                       'Best Parameters':zx},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "gamma_plot = []\n",
    "c_plot = []\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        for kernel in ['rbf','linear']:\n",
    "            svr = SVR(gamma=gamma, C=C)\n",
    "            svr.fit(X_train_reduced,y_train)\n",
    "            train_score_list.append(svr.score(X_train_reduced,y_train))\n",
    "            score = svr.score(X_test_reduced, y_test)\n",
    "            test_score_list.append(score)\n",
    "            gamma_plot.append(gamma)\n",
    "            c_plot.append(C)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_parameters = {'gamma': gamma , 'C' : C,'kernel':kernel}\n",
    "                best_Gamma = gamma\n",
    "                best_C = C\n",
    "                best_kernel = kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svr_cv1 = SVR(gamma = 0.001, C = 100,kernel='rbf')\n",
    "scores = cross_val_score(svr_cv1, X, y, cv = 5, scoring = 'r2')\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "k_range = list(range(1, 11))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, return_train_score=True)\n",
    "\n",
    "# rebuild a model on the combined training and validation set\n",
    "grid_search.fit(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters: {}\".format(grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsRegressor(2)   \n",
    "knn.fit(X_train_reduced,y_train)\n",
    "train_score=knn.score(X_train_reduced,y_train)\n",
    "test_score=knn.score(X_test_reduced,y_test)\n",
    "\n",
    "print('Train score=',train_score,'Test score=',test_score)\n",
    "scores = cross_val_score(knn, X_train_reduced, y_train, cv = 10)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para = reg_model_para.append({'Model_name':'KNN Regression',\n",
    "                                        'Model_params': 'n_neighbors',\n",
    "                                        'Train_score':train_score,'Test_score':test_score,\n",
    "                       'Average Cross Validation Score':grid_search.best_score_,\n",
    "                       'Best Parameters':grid_search.best_params_},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "train = []\n",
    "test= []\n",
    "\n",
    "for alpha in [0.01, 0.1, 1, 10, 100]: \n",
    "    #create the model \n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    #train the model\n",
    "    ridge.fit(X_train_reduced, y_train)\n",
    "    \n",
    "    #evalutation\n",
    "    train.append(ridge.score(X_train_reduced,y_train))\n",
    "    test.append(ridge.score(X_test_reduced, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot([0.01, 0.1, 1, 10, 100], train, label = 'Train score')\n",
    "plt.plot([0.01, 0.1, 1, 10, 100], test, label = 'Test score')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "rdg_reg = Ridge()\n",
    "clf = GridSearchCV(rdg_reg,params,cv=5,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "clf.fit(X_train_reduced,y_train)\n",
    "\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha = 1)\n",
    "ridge.fit(X_train_reduced,y_train)\n",
    "print('Train score: {:.4f}'.format(ridge.score(X_train_reduced,y_train)))\n",
    "print('Test score: {:.4f}'.format(ridge.score(X_test_reduced, y_test)))\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "train_score_list.append(ridge.score(X_train_reduced,y_train))\n",
    "test_score_list.append(ridge.score(X_test_reduced, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Scores.update({'Ridge':scores.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para = reg_model_para.append({'Model_name':'Ridge',\n",
    "                                        'Model_params': 'alpha',\n",
    "                                        'Train_score': ridge.score(X_train_reduced,y_train),'Test_score':ridge.score(X_test_reduced,y_test),\n",
    "                       'Average Cross Validation Score':grid_search.best_score_,\n",
    "                       'Best Parameters':clf.best_params_},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.linear_model import Ridge\n",
    "\n",
    "x_range = [25,10,4,2,1.0,0.8,0.5,0.3,0.2,0.1,0.05,0.02,0.01]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_train_reduced,y_train)\n",
    "    train_score_list.append(ridge.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(ridge.score(X_test_reduced, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x_range, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_range, test_score_list, c = 'b', label = 'Test Score')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc = 3)\n",
    "plt.xlabel(r'$\\alpha$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "x_range1 = np.linspace(0.001, 1, 10000).reshape(-1,1)\n",
    "x_range2 = np.linspace(1, 100000, 10000).reshape(-1,1)\n",
    "\n",
    "x_range = np.append(x_range1, x_range2)\n",
    "coeff = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_train_reduced,y_train)\n",
    "    coeff.append(ridge.coef_ )\n",
    "    \n",
    "coeff = np.array(coeff)\n",
    "\n",
    "for i in range(0,6):\n",
    "    plt.plot(x_range, coeff[:,i], label = 'feature {:d}'.format(i))\n",
    "\n",
    "plt.axhline(y=0, xmin=0.01, xmax=999, linewidth=1, c ='gray')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.5),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "Lasso_reg = Lasso()\n",
    "clf = GridSearchCV(Lasso_reg,params,cv=5,verbose = 1, scoring = 'neg_mean_squared_error')\n",
    "clf.fit(X_train_reduced,y_train)\n",
    "\n",
    "zz = clf.best_params_\n",
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha = 0.01)\n",
    "lasso.fit(X_train_reduced,y_train)\n",
    "print('Train score: {:.4f}'.format(lasso.score(X_train_reduced,y_train)))\n",
    "print('Test score: {:.4f}'.format(lasso.score(X_test_reduced,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Scores.update({'Lasso Regression':grid_search.best_score_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para = reg_model_para.append({'Model_name':'Lasso',\n",
    "                                        'Model_params': 'alpha',\n",
    "                                        'Train_score': lasso.score(X_train_reduced,y_train),'Test_score':lasso.score(X_test_reduced,y_test),\n",
    "                       'Average Cross Validation Score':grid_search.best_score_,\n",
    "                       'Best Parameters':zz},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "x_range1 = np.linspace(0.001, 1, 1000).reshape(-1,1)\n",
    "x_range2 = np.linspace(1, 1000, 1000).reshape(-1,1)\n",
    "\n",
    "x_range = np.append(x_range1, x_range2)\n",
    "coeff = []\n",
    "\n",
    "for alpha in x_range: \n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(X_train_reduced,y_train)\n",
    "    coeff.append(lasso.coef_ )\n",
    "    \n",
    "coeff = np.array(coeff)\n",
    "\n",
    "for i in range(0,6):\n",
    "    plt.plot(x_range, coeff[:,i], label = 'feature {:d}'.format(i))\n",
    "\n",
    "plt.axhline(y=0, xmin=0.001, xmax=9999, linewidth=1, c ='gray')\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.5),\n",
    "          ncol=3, fancybox=True, shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'N': 2}\n",
      "Best score: 0.90\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from  sklearn.preprocessing  import PolynomialFeatures\n",
    "\n",
    "train_score_list = []\n",
    "valid_score_list = []\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for n in range(1,5):\n",
    "    poly = PolynomialFeatures(n)\n",
    "    X_train_poly = poly.fit_transform(X_train_reduced)\n",
    "    X_valid_poly = poly.transform(X_test_reduced)\n",
    "    lreg.fit(X_train_poly, y_train)\n",
    "    train_score_list.append(lreg.score(X_train_poly, y_train))\n",
    "    score = lreg.score(X_valid_poly, y_test)\n",
    "    valid_score_list.append(score)\n",
    "    if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'N': n}\n",
    "            best = n\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x_axis = range(1,5)\n",
    "plt.plot(x_axis, train_score_list, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, valid_score_list, c = 'b', label = 'Validation Score')\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "print(\"Best parameters: {}\".format(best_parameters))\n",
    "print(\"Best score: {:.2f}\".format(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [ 0.80477602  0.92289898  0.92864302 -2.81179442  0.87326579]\n",
      "Average cross-validation score: 0.14\n"
     ]
    }
   ],
   "source": [
    "poly_grid = PolynomialFeatures(best)\n",
    "\n",
    "X_train_poly = poly_grid.fit_transform(X_train_reduced)\n",
    "\n",
    "scores = cross_val_score(LinearRegression(), X_train_poly, y_train, cv = 5, scoring = 'r2')\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))\n",
    "\n",
    "param_grid = {'polynomialfeatures__degree': np.arange(5)}\n",
    "\n",
    "grid_search = GridSearchCV(PolynomialRegression(), param_grid, cv=5, return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "%matplotlib inline\n",
    "x_axis = range(1,6)\n",
    "plt.plot(x_axis, df.mean_train_score, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, df.mean_test_score, c = 'b', label = 'Validation Score')\n",
    "plt.legend()\n",
    "plt.xlabel('degree')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Regression_Scores.update({'Polynomial Regression':scores.mean()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for n in range(1,5):\n",
    "    poly = PolynomialFeatures(n)\n",
    "    X_train_poly = poly.fit_transform(X_train_reduced)\n",
    "    X_test_poly = poly.transform(X_test_reduced)\n",
    "    lreg.fit(X_train_poly, y_train)\n",
    "    train_score_list.append(lreg.score(X_train_poly, y_train))\n",
    "    test_score_list.append(lreg.score(X_test_poly, y_test))\n",
    "    \n",
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para = reg_model_para.append({'Model_name':'Poly regressor',\n",
    "                                        'Model_params': 'degree',\n",
    "                                        'Train_score': train_score_list[1],'Test_score':test_score_list[1],\n",
    "                       'Average Cross Validation Score':grid_search.best_score_,\n",
    "                       'Best Parameters':'{degree:2}'},ignore_index=True)\n",
    "                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: build the model\n",
    "model1 = Sequential()\n",
    "#input layer\n",
    "model1.add(Dense(10, input_dim = 7, activation = 'sigmoid'))\n",
    "#hidden layer\n",
    "#output layer: no activation function\n",
    "model1.add(Dense(1))\n",
    "\n",
    "#step 2: compile the model\n",
    "model1.compile(loss = 'mse', optimizer = 'sgd', metrics = ['mse'])\n",
    "\n",
    "#step 3: train the model\n",
    "model1.fit(X_train_reduced,y_train, epochs = 200, batch_size = 100)\n",
    "\n",
    "#step 4: model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(X_train_reduced, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred = model1.predict(X_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred =  y_pred.reshape(-1,1)\n",
    "r2_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, model1.predict(X_test_reduced))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REGRESSION COMPARISON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_reg_project1=pd.read_csv('result_reg.csv')\n",
    "result_reg_project1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering ``Risk`` as the target column for classification tasks. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset (Risk as target for Classification)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['Audit_Risk','Risk'], axis = 1)\n",
    "y = df['Risk']\n",
    "X.columns\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org, X_test_org, y_train, y_test = train_test_split(X,y, random_state = 0)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train_org)\n",
    "X_test = scaler.transform(X_test_org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(random_state=0, max_depth=1)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbrt.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "y_list = gbrt.feature_importances_\n",
    "y_pos = np.arange(len(y_list))\n",
    "features = X.columns\n",
    "plt.barh(y_pos, y_list, align='center', alpha=0.4)\n",
    "plt.yticks(y_pos, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "log_clf.fit(X_train, y_train)\n",
    "knn_clf = KNeighborsClassifier(2)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "svm_clf = SVC(C = 5, probability = True)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='soft')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('knn', knn_clf), ('svc', svm_clf)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, knn_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=100, bootstrap=True, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib.colors  import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.5, -1, 1.5], alpha=0.5, contour=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plot_decision_boundary(ada_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bagging 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(3)\n",
    "bag_clf = BaggingClassifier(knn_clf, n_estimators=500, max_samples=100, bootstrap=True, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(3)\n",
    "bag_clf = BaggingClassifier(knn_clf, n_estimators=500, max_samples=100, bootstrap=False, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "bag_clf = BaggingClassifier(dt_clf, n_estimators=500, max_samples=100, bootstrap=False, random_state=0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "print('Train score: {:.2f}'.format(bag_clf.score(X_train, y_train)))\n",
    "print('Test score: {:.2f}'.format(bag_clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=0)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.5, random_state=0)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "plot_decision_boundary(ada_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.95)\n",
    "pca.fit(X_train)\n",
    "pca.fit(X_test)\n",
    "#pca.fit(y_train.reshape(1, -1))\n",
    "#pca.fit(y_test.reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced = pca.transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "#y_test_reduced = pca.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN classifier on reduced pca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID_SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_array = []\n",
    "test_array = []\n",
    "x_axis = range(1,20)\n",
    "\n",
    "for k in range(1,20):\n",
    "    knn=KNeighborsClassifier(k)   \n",
    "    knn.fit(X_train_reduced,y_train)\n",
    "    train_score=knn.score(X_train_reduced,y_train)\n",
    "    test_score=knn.score(X_test_reduced,y_test)\n",
    "    train_array.append(train_score)\n",
    "    test_array.append(test_score)\n",
    "\n",
    "line1, = plt.plot(x_axis, train_array, c='g', label = 'Train')\n",
    "line2, = plt.plot(x_axis, test_array, c='b', label = 'Test')\n",
    "plt.axis()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(handles = [line1, line2],loc = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_neighbors':[1,2,3,4,5,6,7,8,9]}\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "model = GridSearchCV(knn, params, cv=5)\n",
    "model.fit(X_train_reduced,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN_ALGORITHIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(9)   \n",
    "knn.fit(X_train_reduced,y_train)\n",
    "train_score=knn.score(X_train_reduced,y_train)\n",
    "test_score=knn.score(X_test_reduced,y_test)\n",
    "print('Train score=',train_score,'Test score=',test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 11))\n",
    "\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "df = pd.DataFrame(grid_search.cv_results_)\n",
    "%matplotlib inline\n",
    "x_axis = range(1,11)\n",
    "plt.plot(x_axis, df.mean_train_score, c = 'g', label = 'Train Score')\n",
    "plt.plot(x_axis, df.mean_test_score, c = 'b', label = 'Test Score')\n",
    "plt.legend()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('MSE')\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(knn, X, y, cv = 6)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = knn.predict(X_test_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,pred_knn)\n",
    "\n",
    "print ('Recall    : {}'.format(recall[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "Classification_Scores={}\n",
    "\n",
    "Classification_Scores.update({'KNN Classification':[metrics.accuracy_score(y_test,pred_knn),recall[1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Classifier','Best Parameters','Accuracy_Score','Recall']\n",
    "clf_model_para = pd.DataFrame(columns=columns)\n",
    "\n",
    "clf_model_para=clf_model_para.append({'Classifier':'KNN Classification',\n",
    "                                      'Best Parameters':grid_search.best_params_,\n",
    "                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_knn),\n",
    "                                      'Recall':recall[1]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC LINEAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID_SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        svc_lin = SVC(kernel='linear', gamma=gamma, C=C)\n",
    "        svc_lin.fit(X_train_reduced,y_train)\n",
    "        train_score_list.append(svc_lin.score(X_train_reduced,y_train))\n",
    "        score = svc_lin.score(X_test_reduced, y_test)\n",
    "        test_score_list.append(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'gamma': gamma , 'C' : C}\n",
    "            best_Gamma = gamma\n",
    "            best_C = C\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_train_reduced, y_train)\n",
    "test_score = svm.score(X_test_reduced, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_lin_cv = SVC(kernel='linear',gamma = best_Gamma, C = best_C)\n",
    "scores = cross_val_score(svc_lin_cv,X, y, cv = 5, scoring = 'r2')\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_lin = svc_lin.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,pred_svm_lin)\n",
    "\n",
    "print ('Recall    : {}'.format(recall[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_Scores.update({'Linear_SVC':[metrics.accuracy_score(y_test,pred_svm_lin),recall[1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_para=clf_model_para.append({'Classifier':'Linear_SVC',\n",
    "                                      'Best Parameters':grid_search.best_params_,\n",
    "                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_svm_lin),\n",
    "                                      'Recall':recall[1]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "c_range = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "train_score_l1 = []\n",
    "train_score_l2 = []\n",
    "valid_score_l1 = []\n",
    "valid_score_l2 = []\n",
    "\n",
    "best_score = 0\n",
    "l1 = 'l1'\n",
    "l2 = 'l2'\n",
    "\n",
    "for c in c_range:\n",
    "    log_l1 = LogisticRegression(penalty = 'l1', C = c)\n",
    "    log_l2 = LogisticRegression(penalty = 'l2', C = c)\n",
    "    \n",
    "    log_l1.fit(X_train_reduced, y_train)\n",
    "    log_l2.fit(X_train_reduced, y_train)\n",
    "    \n",
    "    train_score_l1.append(log_l1.score(X_train_reduced, y_train))\n",
    "    train_score_l2.append(log_l2.score(X_train_reduced, y_train))\n",
    "    \n",
    "    score = log_l1.score(X_test_reduced, y_test)\n",
    "    valid_score_l1.append(score)\n",
    "    if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': c , 'penalty': l1}\n",
    "            best_C = c\n",
    "            best_Penalty = 'l1'\n",
    "    \n",
    "    score = log_l2.score(X_test_reduced, y_test)\n",
    "    valid_score_l2.append(score)\n",
    "    if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'C': c , 'penalty' : l2}\n",
    "            best_C = c\n",
    "            best_Penalty = 'l2'\n",
    "    \n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(c_range, train_score_l1, label = 'Train score, penalty = l1')\n",
    "plt.plot(c_range, valid_score_l1, label = 'Test score, penalty = l1')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(c_range, train_score_l2, label = 'Train score, penalty = l2')\n",
    "plt.plot(c_range, valid_score_l2, label = 'Test score, penalty = l2')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_grid = LogisticRegression(penalty = best_Penalty, C = best_C)\n",
    "\n",
    "scores = cross_val_score(log_grid, X_train_reduced, y_train, cv =5, scoring = 'accuracy')\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1','l2'],\n",
    "             'C':  [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(max_iter=10000), param_grid, cv=5, return_train_score=True)\n",
    "\n",
    "grid_search.fit(X_train_reduced, y_train)\n",
    "\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "pred_log = grid_search.predict(X_test_reduced)\n",
    "print(metrics.accuracy_score(y_test,pred_log))\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_log)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "print(classification_report(y_test,pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,pred_log)\n",
    "\n",
    "print ('Recall    : {}'.format(recall[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_Scores.update({'Logistic Classification':[metrics.accuracy_score(y_test,pred_log),recall[1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_para=clf_model_para.append({'Classifier':'Logistic Classification',\n",
    "                                      'Best Parameters':grid_search.best_params_,\n",
    "                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_log),\n",
    "                                      'Recall':recall[1]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        svc_rbf = SVC(kernel='rbf', gamma=gamma, C=C)\n",
    "        svc_rbf.fit(X_train_reduced,y_train)\n",
    "        train_score_list.append(svc_rbf.score(X_train_reduced,y_train))\n",
    "        score = svc_rbf.score(X_test_reduced, y_test)\n",
    "        test_score_list.append(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'gamma': gamma , 'C' : C}\n",
    "            best_Gamma = gamma\n",
    "            best_C = C\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_train_reduced, y_train)\n",
    "test_score = svm.score(X_test_reduced, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_rbf_cv = SVC(kernel='rbf',gamma = best_Gamma, C = best_C)\n",
    "scores = cross_val_score(svc_rbf_cv, X, y, cv = 6, scoring = 'r2')\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_rbf = svc_rbf.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_Scores.update({'SVC RBF Kernel':[metrics.accuracy_score(y_test,pred_svm_rbf),recall[1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_para=clf_model_para.append({'Classifier':'SVC RBF Kernel',\n",
    "                                      'Best Parameters':grid_search.best_params_,\n",
    "                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_svm_rbf),\n",
    "                                      'Recall':recall[1]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svc_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for degree in range(1,5):\n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        svc_poly = SVC(kernel='poly', degree = degree, C=C, gamma = 'auto')\n",
    "        svc_poly.fit(X_train_reduced,y_train)\n",
    "        train_score_list.append(svc_poly.score(X_train_reduced,y_train))\n",
    "        score = svc_poly.score(X_test_reduced, y_test)\n",
    "        test_score_list.append(score)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters = {'degree': degree , 'C' : C}\n",
    "            best_Degree = degree\n",
    "            best_C = C\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(**best_parameters)\n",
    "svm.fit(X_train_reduced, y_train)\n",
    "test_score = svm.score(X_test_reduced, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_poly_cv = SVC(kernel='poly',degree = best_Degree, C=best_C, gamma = 'auto')\n",
    "scores = cross_val_score(svc_poly_cv, X,y, cv = 6, scoring = 'r2')\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_poly = svc_poly.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_Scores.update({'SVC Poly Kernel':[metrics.accuracy_score(y_test,pred_svm_poly),recall[1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_para=clf_model_para.append({'Classifier':'SVC Poly Kernel',\n",
    "                                      'Best Parameters':grid_search.best_params_,\n",
    "                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_svm_poly),\n",
    "                                      'Recall':recall[1]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "dtree.fit(X_train_reduced, y_train)\n",
    "print(\"Accuracy on training set: {:.3f}\".format(dtree.score(X_train_reduced, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(dtree.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_cv = DecisionTreeClassifier()\n",
    "scores = cross_val_score(dtree_cv, X_train_reduced, y_train, cv = 5, scoring = 'accuracy' )\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tree = dtree.predict(X_test_reduced)\n",
    "print(metrics.accuracy_score(y_test,pred_tree))\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_tree)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))\n",
    "\n",
    "print(classification_report(y_test,pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,pred_tree)\n",
    "\n",
    "print ('Recall    : {}'.format(recall[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification_Scores.update({'Decison Tree':[metrics.accuracy_score(y_test,pred_tree),recall[1]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_para=clf_model_para.append({'Classifier':'Decision Tree',\n",
    "                                      'Best Parameters':' ',\n",
    "                                      'Accuracy_Score':metrics.accuracy_score(y_test,pred_tree),\n",
    "                                      'Recall':recall[1]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_tree)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "y2 = y == 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "dummy_majority = DummyClassifier(strategy='most_frequent')\n",
    "dummy_majority.fit(X_train, y_train)\n",
    "\n",
    "pred_most_frequent = dummy_majority.predict(X_test)\n",
    "\n",
    "print(\"Unique predicted labels: {}\".format(np.unique(pred_most_frequent)))\n",
    "print(\"Test score: {:.2f}\".format(dummy_majority.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dummy = DummyClassifier().fit(X_train_reduced, y_train)\n",
    "pred_dummy = dummy.predict(X_test_reduced)\n",
    "print(\"dummy score: {:.2f}\".format(dummy.score(X_test_reduced, y_test)))\n",
    "\n",
    "logreg = LogisticRegression(C=0.1).fit(X_train_reduced, y_train)\n",
    "pred_logreg = logreg.predict(X_test_reduced)\n",
    "print(\"logreg score: {:.2f}\".format(logreg.score(X_test_reduced, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = knn.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_lin = svc_lin.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_rbf = svc_rbf.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm_poly = svc_poly.predict(X_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, pred_logreg)\n",
    "print(\"Confusion matrix:\\n{}\".format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Most frequent class:\")\n",
    "print(confusion_matrix(y_test, pred_most_frequent))\n",
    "print(\"\\nDummy model:\")\n",
    "print(confusion_matrix(y_test, pred_dummy))\n",
    "print(\"\\nDecision tree:\")\n",
    "print(confusion_matrix(y_test, pred_tree))\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(confusion_matrix(y_test, pred_logreg))\n",
    "print(\"\\nKNN\")\n",
    "print(confusion_matrix(y_test, pred_knn))\n",
    "print(\"\\nSVMLinear\")\n",
    "print(confusion_matrix(y_test, pred_svm_lin))\n",
    "print(\"\\nSVMrbf\")\n",
    "print(confusion_matrix(y_test, pred_svm_rbf))\n",
    "print(\"\\nSVMpoly\")\n",
    "print(confusion_matrix(y_test, pred_svm_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"f1 score most frequent: {:.2f}\".format(f1_score(y_test, pred_most_frequent)))\n",
    "print(\"f1 score dummy: {:.2f}\".format(f1_score(y_test, pred_dummy)))\n",
    "print(\"f1 score tree: {:.2f}\".format(f1_score(y_test, pred_tree)))\n",
    "print(\"f1 score logistic regression: {:.2f}\".format(f1_score(y_test, pred_logreg)))\n",
    "print(\"f1 score KNN Classifier: {:.2f}\".format(f1_score(y_test, pred_knn)))\n",
    "print(\"f1 score Svc Linear: {:.2f}\".format(f1_score(y_test, pred_svm_lin)))\n",
    "print(\"f1 score Svc rbf: {:.2f}\".format(f1_score(y_test, pred_svm_rbf)))\n",
    "print(\"f1 score SVc poly: {:.2f}\".format(f1_score(y_test, pred_svm_poly)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_most_frequent, target_names=[\"No Risk\", \"Risk\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_tree, target_names=[\"No Risk\", \"Risk\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_logreg, target_names=[\"No Risk\", \"Risk\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_knn, target_names=[\"No Risk\", \"Risk\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_svm_lin, target_names=[\"No Risk\", \"Risk\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_svm_rbf, target_names=[\"No Risk\", \"Risk\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, pred_svm_poly, target_names=[\"No Risk\", \"Risk\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svc = SVC(**best_parameters)\n",
    "svc.fit(X_train_reduced, y_train)\n",
    "test_score = svm.score(X_test_reduced, y_test)\n",
    "print(\"Best score on validation set: {:.2f}\".format(best_score))\n",
    "print(\"Best parameters: \", best_parameters)\n",
    "print(\"Test set score with best parameters: {:.2f}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, svc.decision_function(X_test_reduced))\n",
    "\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.plot(precision, recall, label=\"precision recall curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, max_features=2)\n",
    "rf.fit(X_train_reduced, y_train)\n",
    "\n",
    "# RandomForestClassifier has predict_proba, but not decision_function\n",
    "precision_rf, recall_rf, thresholds_rf = precision_recall_curve(y_test, rf.predict_proba(X_test_reduced)[:, 1])\n",
    "\n",
    "plt.plot(precision, recall, label=\"svc\")\n",
    "\n",
    "plt.plot(precision[close_zero], recall[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero svc\", fillstyle=\"none\", c='k', mew=2)\n",
    "\n",
    "plt.plot(precision_rf, recall_rf, label=\"rf\")\n",
    "\n",
    "close_default_rf = np.argmin(np.abs(thresholds_rf - 0.5))\n",
    "plt.plot(precision_rf[close_default_rf], recall_rf[close_default_rf], '^', c='k',\n",
    "         markersize=10, label=\"threshold 0.5 rf\", fillstyle=\"none\", mew=2)\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"f1_score of random forest: {:.3f}\".format(f1_score(y_test, rf.predict(X_test_reduced))))\n",
    "\n",
    "print(\"f1_score of svc: {:.3f}\".format(f1_score(y_test, svm.predict(X_test_reduced))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, svc.decision_function(X_test_reduced))\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "# find threshold closest to zero\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize=10,\n",
    "         label=\"threshold zero\", fillstyle=\"none\", c='k', mew=2)\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "plt.figure()\n",
    "for gamma in [1, 0.1, 0.01]:\n",
    "    svc = SVC(gamma=gamma).fit(X_train_reduced, y_train)\n",
    "    accuracy = svc.score(X_test_reduced, y_test)\n",
    "    auc = roc_auc_score(y_test, svc.decision_function(X_test_reduced))\n",
    "    fpr, tpr, _ = roc_curve(y_test , svc.decision_function(X_test_reduced))\n",
    "    print(\"gamma = {:.2f}  accuracy = {:.2f}  AUC = {:.2f}\".format(gamma, accuracy, auc))\n",
    "    plt.plot(fpr, tpr, label=\"gamma={:.3f}\".format(gamma))\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.xlim(-0.01, 1)\n",
    "plt.ylim(0, 1.02)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: build model\n",
    "model1 = Sequential()\n",
    "#input layer\n",
    "model1.add(Dense(10, input_dim = 29, activation = 'relu'))\n",
    "#hidden layers\n",
    "#output layer\n",
    "model1.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#step 2: make computational graph - compile\n",
    "model1.compile(loss= 'binary_crossentropy' , optimizer = 'adam',metrics = ['accuracy'] )\n",
    "\n",
    "#step 3: train the model - fit\n",
    "model1.fit(X_train, y_train, epochs = 50, batch_size = 300)\n",
    "\n",
    "#step 4: evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: build model\n",
    "model2 = Sequential()\n",
    "#input layer\n",
    "model2.add(Dense(20, input_dim = 29, activation = 'relu'))\n",
    "#hidden layers\n",
    "model2.add(Dense(10, activation = 'relu'))\n",
    "model2.add(Dense(5, activation = 'relu'))\n",
    "#output layer\n",
    "model2.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#step 2: compile the model\n",
    "model2.compile(loss= 'binary_crossentropy' , optimizer = 'adam',metrics = ['accuracy'] )\n",
    "\n",
    "#step 3: train the model\n",
    "model2.fit(X_train, y_train, epochs = 30, batch_size = 150)\n",
    "\n",
    "#step 4: evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFACTION COMPARISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_model_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_classification_project1=pd.read_csv('result_classification.csv')\n",
    "result_classification_project1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
